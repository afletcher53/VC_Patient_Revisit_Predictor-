{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from configuration import Config, FilePaths\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set seeds to ensure reproduceability\n",
    "np.random.seed(Config.seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(Config.seed)\n",
    "\n",
    "FILE_PATHS = FilePaths()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organise data from Vetcompass' EHRs into a pandas dataframe, where each row represents a single patient, and each column represents a calendar day of the year.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the saved CSV's from VetCompass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all three CSVs into a pandas data frame (I was provided with a combined_documents.csv, secondary_patient_level_annotations.csv and a secondary_problem_level_annotations.csv)\n",
    "for i in tqdm(range(0, 3), ncols=100, desc=\"Loading data..\"):\n",
    "    raw_df_as_read = pd.read_csv(FILE_PATHS.RAW_DATA)\n",
    "    patient_level_annotations_as_read = pd.read_csv(FILE_PATHS.PATIENT_LEVEL_DATA)\n",
    "    problem_level_annotations_as_read = pd.read_csv(FILE_PATHS.PROBLEM_LEVEL_DATA)\n",
    "print(\"------Loading is completed ------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are given lots of extraeneous information, so lets strip non relavent data. Note that patient ID is unique to each patient. \n",
    "- Firstly we create a copy of the data, create an additional column called Date which contains the date record was made\n",
    "- Then we drop unnessicary columns, and filter all records by the study date (1/1/2019 -> 31/12/2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df_as_read.copy()\n",
    "\n",
    "# Then we split the recorded date to DateTimeDay column, so we can get concat records existing on a single day\"\n",
    "raw_df[[\"DateTimeDay\", \"DateTimeSeconds\"]] = raw_df[\"RecordedDate\"].str.split(\n",
    "    \"T\", expand=True\n",
    ")\n",
    "raw_df[\"Date\"] = pd.to_datetime(raw_df[\"DateTimeDay\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "raw_df.drop(\n",
    "    Config.raw_data_columns_drop, axis=1, inplace=True, errors=\"ignore\"\n",
    ")  # Drop un-needed columns\n",
    "raw_df = raw_df[\n",
    "    (raw_df[\"Date\"] >= Config.study_start_date)\n",
    "    & (raw_df[\"Date\"] <= Config.study_end_date)\n",
    "]  # Only include patients withint study start date\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_level_annotations = patient_level_annotations_as_read.copy()\n",
    "patient_level_annotations.drop(Config.patient_level_columns_drop, axis=1, inplace=True)\n",
    "patient_level_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_patients = set(\n",
    "    patient_level_annotations.loc[\n",
    "        patient_level_annotations[\"Is this patient included in the study_1\"] == \"Yes\",\n",
    "        \"PatientID\",\n",
    "    ].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_level_annotations = problem_level_annotations_as_read.copy()\n",
    "\n",
    "# Drop all patients NOT in study\n",
    "problem_level_annotations = problem_level_annotations[\n",
    "    problem_level_annotations.PatientID.isin(study_patients)\n",
    "]\n",
    "\n",
    "problem_level_annotations[\n",
    "    [\"DateTimeDay\", \"DateTimeSeconds\"]\n",
    "] = problem_level_annotations[\"DocumentDate\"].str.split(\" \", expand=True)\n",
    "problem_level_annotations[\"Date\"] = pd.to_datetime(\n",
    "    problem_level_annotations[\"DateTimeDay\"], format=\"%d/%m/%Y\"\n",
    ")\n",
    "\n",
    "problem_level_annotations.drop(Config.problem_level_columns_drop, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function to check if we have multiple entries per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multiple_entries(df) -> list:\n",
    "    \"Check there are not multiple entries per day, if so remove these days from the data pool\"\n",
    "    multiple_entries_list = []\n",
    "    for i in set(df.PatientID.tolist()):\n",
    "        results = df.loc[df.PatientID == i]\n",
    "        if not results.Date.is_unique:\n",
    "            multiple_entries_list.append(i)\n",
    "    return multiple_entries_list\n",
    "\n",
    "\n",
    "df = problem_level_annotations[\n",
    "    ~problem_level_annotations.PatientID.isin(\n",
    "        check_multiple_entries(problem_level_annotations)\n",
    "    )\n",
    "]\n",
    "\n",
    "if len(check_multiple_entries(df)) != 0:\n",
    "    raise Exception(\"Sorry, but it appears you have multiple categorised days!\")\n",
    "\n",
    "print(f\"You have {len(df.PatientID.unique())} patients included in this study\")\n",
    "print(f\"and a total of {len(df.index)} 24 hour periods classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the EHRs to the DF\n",
    "ehrs = []\n",
    "for index, row in df.iterrows():\n",
    "    ehr = raw_df[(raw_df.PatientId == row.PatientID) & (raw_df.Date == row.Date)]\n",
    "    ehr_list = ehr.Document.to_list()\n",
    "    ehrs.append(\" \".join(ehr_list))\n",
    "\n",
    "df.loc[:, \"ehr\"] = ehrs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the patient visits\n",
    "df_patients_visits = df[df[Config.is_visit_column] == \"Yes\"].copy()\n",
    "patient_id_set: set = set(df_patients_visits[Config.patient_id_column].values)\n",
    "\n",
    "tmp_list: list = []\n",
    "\n",
    "print(f\"{len(patient_id_set)} patients included in this study who had a visit\")\n",
    "\n",
    "df_patients_visits[\"DOY\"] = df_patients_visits[\"Date\"].dt.dayofyear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of the patients EHR, by replacing the day of year of a premade string with the EHR textual input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_stream_list: list = []\n",
    "patient_id_list: list = []\n",
    "for patient_id in patient_id_set:\n",
    "    patient_stream: list = [str(x) for x in range(1, 365 + 1)]\n",
    "    patient_id_list.append(patient_id)\n",
    "    patient_records = df_patients_visits.loc[\n",
    "        df_patients_visits[Config.patient_id_column] == patient_id\n",
    "    ]\n",
    "    for i in range(len(patient_records)):\n",
    "        patient_stream[\n",
    "            patient_records.iloc[[i]].DOY.values[0] - 1\n",
    "        ] = patient_records.iloc[[i]].ehr.values[0]\n",
    "    ehr_stream_list.append(patient_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restructured_df = pd.DataFrame(ehr_stream_list)\n",
    "restructured_df.set_axis(patient_id_list, inplace=True)\n",
    "restructured_df.index.name = \"Patient Id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restructured_df.to_csv(FILE_PATHS.REARRANGED_DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final CSV file has been saved with a patients EHR timestream being predicted as a row. \n",
    "Windowing should occur next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6f07f10bbd904384622e2c81da346bac6398da26490ea76cc729ffb1c8c49fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
